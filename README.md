# HSEA 第四次作业

## 代码运行方法和结构说明

直接在代码根目录文件中运行如下内容即可

- POSS 算法

  ```bash
  $ python main.py
  ```

- NSGA-ii 算法

  ```bash
  $ python nsga_main.py
  ```

- MOEA/D 算法

  ```bash
  $ python moead_main.py
  ```

**代码结构说明**

```bash
.
├── data					# 数据集文件
│   ├── ionosphere
│   ├── sonar
│   ├── svmguide3_1.csv
│   ├── svmguide3.csv
│   └── triazines.csv
├── demo.ipynb				# 测试用的demo，于本次任务无关
├── main.py					# 用于运行 POSS 算法的文件
├── modules.py				# 包含了POSS，NSGA，MOEA/D算法类的文件，通过在xxx_main.py 中调用使用
├── moead_main.py			# 用于运行MOEA/D 算法的文件
├── nsga_main.py			# 用于运行NSGA-ii 算法的文件
└── utils.py				# 实现了一个调用数据集的 DataLoader 类

```

## Task 1

#### 算法实现简述

以下所有的演化算法的目的都是想对于一个线性回归问题 $\mathcal{F}: X\to Y$, 得到一个$X$ 的子集合来做稀疏化的线性回归问题，也即优化的目标是:
$$
	\min \{f(X), |X|\}
$$
其中 $f(X)$ 为原有的线性回归问题的优化目标(此处为MSE)，而$|X|$是用于限定$X$ 集合的大小的。类似的，可以理解为一个加入了正则化项的一个优化问题。

一般的多目标优化问题，是基于Pareto 前沿的优化问题，如在NSGA-ii 算法中每一轮迭代都需要计算一次 Pareto前沿，而在POSS算法中，保证了种群中只包含Pareto前沿，也就是说每次产生的的子代解若被当前的种群所控制，则不会更新到种群中，减少了很多的运算量。

在实验中也可得到如下的一个运算量级表：

| 算法    | 运算速度(迭代轮/s) |
| ------- | ------------------ |
| POSS    | 1750               |
| NSGA-ii | 14                 |
| MOEA/D  | 1.34               |

也证明了POSS对于如何获得Pareto前沿的处理显著的减少了运算量



同时POSS中有基于$R^2$的运算，也即为$\dfrac{Var[z]-MSE[Z,S]}{Var[z]}$, 也即当$Var[z] = 1$ ，$\mathbb{E}[Z]=0$,时即可使用 $1 - mse$ 来替代 $R^2$的运算，减小运算代价

#### 运行结果

在四个数据集上运行得到的关于mse的收敛的图像如下:

(值得注意的是，除了sonar数据集做了归一化之外，其他数据集都因为`np.std(x)`过小而没有进行归一化)

#### 分析

但是不同于NSGA-ii和MOEA/D的运行速度较慢，POSS算法需要更多的训练轮数来直至收敛，但是总体上的耗时来看，还是POSS算法是最快的。

## Task 2

#### NSGA-ii

##### 方法实现简述

NSGA-ii 算法的核心是在保证演化获得的解尽可能的接近Pareto前沿的同时，在同一层级上选择最有多样性的解，也就是说约定了对于解的评估上优先级是先取接近pareto前沿的解，而后取同一层级上的更为兼顾多个指标$f_i$ 的解

在代码中的核心体现就是两个函数 `fast_non_dominated_sort` 来获得本次种群中的pareto前沿，而后利用`crowdingDist` 来得到更为兼顾多个指标的解。

而在一般的演化算法的基础上，只是在获得survivor的时候使用上述的方式来进行评估，而非原有的单纯的基于Fiteness函数来进行评估的过程。

但是可以注意到在NSGA-ii的每一轮演化的过程中，都会计算一个Pareto前沿，这个过程粗略的计算有$O(n^2)$ 的复杂度，耗时还是很巨大的，但是也可以利用一些处理方法消除到$O(n)$ 左右的复杂度

##### 运行结果

##### 分析

实际运行下来看得话，NSGA-ii 结构简单，运行的结果也很稳定。但是最大的问题就是其运行时间较长，同时其获得的解集在评价函数上的数值表现的较差。可能是因为在Pareto前沿上的解在状态空间中张的很平均，不能很好的利用状态空间中的一些解之间的相关性信息，使得更新的过程较为的缓慢。

#### MOEA/D

##### 方法实现简述

MOEA/D 算法的核心思想是状态空间$S\in R^{m}$, 其中 $m$ 是多目标优化函数$f_i$的数目，而MOEA/D的想法是利用一系列的$\lambda$ 作为参数控制在状态空间中以$\lambda F$ 来张一系列的方向，如果$\lambda $ 的初始化控制的比较好的话，会较好的张满状态空间，而假设$\lambda$ 相近的方向其在Pareto前沿上有一定的相近性。同时把所有的pareto前沿都储存下来。则在每次产生新的子代解的时候，只需要同其‘’邻居‘’ 进行比较，而同时更新pareto前沿的时候若被更新的解在pareto前沿中则直接更新即可，相较与NSGA-ii算法可以减少计算量。同时可以获得更好的解集

##### 运行结果

- Sonar

  ![sonar_moead](pic/sonar_moead.png)

- Svmguide3

  ![svm_moead](pic/svm_moead.png)

- Ionosphere

  ![ionosphere_moead](pic/ionosphere_moead.png)

- Triazines

  ![triaz_moead](pic/triaz_moead.png)

##### 分析

但是在实际的实验过程中，发现MOEA/D算法有一些特性:

1. 其对于用于分解状态空间的$\lambda$ 的初始化高度的敏感，严重影响演化算法的施行
2. 因为MOEA/D有对于其*邻居*有更新的行为，在某一次演化过程中获得一个较好的解的时候会迅速的**传染**到所有的子问题或者叫做种群之上，比较的容易陷入局部最优解。表现出来到结果就是其最终获得的Pareto前沿的数量较少。也可能是我个人是实现方法的更新的问题

## 实验心得

1. 在使用本次实验的多目标演化算法来解决稀疏线性回归的问题时，颇有一种进行特征工程做特征子集选择的感觉。在使用包括式的框架下，其每一次迭代中都会使用目标模型来进行评估(在本次实验上就是反复训练一个线性回归模型来获得mse)，运算的复杂度较高，感觉是否可以优化一下。

   因为看出演化算法严重的依赖于Fitness函数的运算速度，是否有一些方法如贝叶斯网等模型对于演化的方向有一些指引性的多目标演化的框架工作

2. 演化算法中关于演化轮数的约定感觉很是一个问题，因为一些模型如MOEA/D更新种群的速度相当的快，若演化轮数设计的较多的话会迅速的把所有的解融合到唯一的解上，之后就很难做演化了，也是一个问题。

#### 参考工作

- MOEA/D 的理解和讲解参考了https://blog.csdn.net/jiang425776024/article/details/84635353 的工作，尤其是关于 $\lambda$ 的初始化部分参考了他的实现方式。我个人的原始版本为一个:

  ```python
  w = np.random.rand(size)
  w /= np.sum(w)
  ```

  但是效果并不好，并且不是很分散

  还用就是MOEA/D 的原始论文 https://ieeexplore.ieee.org/document/4358754 中第二节的伪代码部分的框架

- POSS部分的代码是根据给定的Matlab代码翻译的，而NSGA-ii部分是根据课件的讲解实现的
